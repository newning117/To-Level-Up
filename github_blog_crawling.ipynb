{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1YcRfYL0XA6p8xzwmv6XHJ26-OGNz4pDB",
      "authorship_tag": "ABX9TyO5I8jZcfnynbO5c+qNdIjt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/newning117/Blog-Crawling/blob/main/github_blog_crawling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ** 00 ë¸”ë¡œê·¸ ìˆ˜ì¹˜_2025ë…„ 00ì›” 00ì¼ 00ì‹œ 00ë¶„ ê¸°ì¤€**\n",
        "\n",
        "<íë¦„ ì •ë¦¬>\n",
        "\n",
        "**A. Colabì—ì„œ í¬ë¡¤ë§ ì‹¤í–‰ ë° DataFrame ìƒì„±**\n",
        "    \n",
        "    1. url\n",
        "    2. date\n",
        "    3. title\n",
        "    4. comment_count\n",
        "    5. like_count\n",
        "\n",
        "**B. 1â€“5ë²ˆ ìˆ˜ì¹˜ ì‚°ì¶œ**\n",
        "\n",
        "    1. ì´ ê²Œì‹œë¬¼ ìˆ˜\n",
        "    2. ì´ ëŒ“ê¸€ ìˆ˜\n",
        "    3. ì´ ì¢‹ì•„ìš” ìˆ˜\n",
        "    4. ê²Œì‹œë¬¼ 1ê±´ ë‹¹ í‰ê·  ëŒ“ê¸€ ìˆ˜\n",
        "    5. ê²Œì‹œë¬¼ 1ê±´ ë‹¹ í‰ê·  ì¢‹ì•„ìš” ìˆ˜\n",
        "\n",
        "**C\\. ì¶”ê°€ ê¸°ì´ˆ ì§€í‘œ**\n",
        "\n",
        "    1. \tëŒ“ê¸€/ê³µê° ë¶„í¬ (ì¤‘ì•™ê°’, ë¶„ìœ„ìˆ˜, 0ê°œ ë¹„ìœ¨)\n",
        "\t2.\tì‹œê°„ì¶•(ì—°ë„/ì›”ë³„, ìµœê·¼ 6~12ê°œì›” ê¸°ì¤€) ì§€í‘œ\n",
        "\t3.\tê³µê°/ëŒ“ê¸€ TOP N / LOW N ë¦¬ìŠ¤íŠ¸\n",
        "\t4.\tíƒœê·¸ë‚˜ ì£¼ì œë³„ ìš”ì•½ (ê°€ëŠ¥í•´ì§€ë©´)"
      ],
      "metadata": {
        "id": "vJ98M43IS-h4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **A. Colabì—ì„œ í¬ë¡¤ë§ ì‹¤í–‰**"
      ],
      "metadata": {
        "id": "7s-IC6DYT_7q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##A-1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
      ],
      "metadata": {
        "id": "VkngvaiJUVZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "aAsTNnLShsGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JkhCltdMsgY"
      },
      "outputs": [],
      "source": [
        "!pip install beautifulsoup4 gspread\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ],
      "metadata": {
        "id": "tlMlevJnUY6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A-2. list_page*.html ì—ì„œ logNoë§Œ ë½‘ê¸° (JSON/HTML ë‘˜ ë‹¤ ëŒ€ì‘)"
      ],
      "metadata": {
        "id": "vfGOC32AUOwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests, json, re, html as html_lib\n",
        "\n",
        "BASE_BLOG = \"https://blog.naver.com\"\n",
        "BLOG_ID = #\"ğŸ‘‰â­ï¸í•´ë‹¹ ë¸”ë¡œê·¸ ì•„ì´ë”” ê¸°ì¬\"\n",
        "\n",
        "HEADERS = {\n",
        "    #\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 \"\n",
        "                  #\"(KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36\",\n",
        "} #ğŸ‘‰â­ï¸ì‚¬ìš©ìì˜ User-Agent ê¸°ì¬\n",
        "\n",
        "# âœ… ì €ì¥í•  í´ë” (êµ¬ê¸€ ë“œë¼ì´ë¸Œ)\n",
        "SAVE_DIR = #\"ğŸ‘‰â­ï¸/content/drive ì €ì¥ ê²½ë¡œ ê²½ë¡œ ê¸°ì¬ \"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "print(\"ì €ì¥ ê²½ë¡œ:\", SAVE_DIR)\n",
        "\n",
        "post_lognos = set()\n",
        "\n",
        "# 1~12í˜ì´ì§€ ì •ë„ë©´ 299ê°œ ê¸€ ì»¤ë²„ (í•„ìš”í•˜ë©´ range ë ìˆ«ì ëŠ˜ë¦¬ë©´ ë¨)\n",
        "for page in range(1, 20): #ğŸ‘‰â­ï¸ëª©ë¡ ë¦¬ìŠ¤íŠ¸ì˜ í˜ì´ì§€ ê°œìˆ˜ë¥¼ 1~20í˜ì´ì§€ê¹Œì§€ ì„¤ì •í•œë‹¤ëŠ” ì˜ë¯¸ë¡œ í•„ìš”ì— ë”°ë¼ 20ì„ ë‹¤ë¥¸ ìˆ˜ë¡œ ë³€ê²½\n",
        "    url = (\n",
        "        \"https://blog.naver.com/PostTitleListAsync.naver\"\n",
        "        f\"?blogId={BLOG_ID}&viewdate=&currentPage={page}\"\n",
        "        \"&categoryNo=0&parentCategoryNo=&countPerPage=30\" #PerPage=30 -> 1í˜ì´ì§€ë‹¹ 30ê°œ ëª©ë¡ì„ ì˜ë¯¸\n",
        "    )\n",
        "    print(f\"\\n[ìš”ì²­] page={page} ->\", url)\n",
        "    res = requests.get(url, headers=HEADERS)\n",
        "    print(\"  status:\", res.status_code)\n",
        "\n",
        "    if res.status_code != 200:\n",
        "        print(\"  âš ï¸ 200ì´ ì•„ë‹ˆë¼ì„œ ì´ í˜ì´ì§€ëŠ” ìŠ¤í‚µ:\", res.text[:80])\n",
        "        continue\n",
        "\n",
        "    text = res.text.strip()\n",
        "\n",
        "    # âœ… 1) ë°›ì€ ì‘ë‹µì„ ê·¸ëŒ€ë¡œ html íŒŒì¼ë¡œ ì €ì¥\n",
        "    save_path = os.path.join(SAVE_DIR, f\"list_page{page}.html\")\n",
        "    with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(text)\n",
        "    print(\"  ğŸ‘‰ íŒŒì¼ ì €ì¥ ì™„ë£Œ:\", save_path)\n",
        "\n",
        "    # âœ… 2) logNo ì¶”ì¶œ ë¡œì§\n",
        "    if text.startswith(\"{\"):\n",
        "        # JSON ì‘ë‹µì¼ ê°€ëŠ¥ì„±\n",
        "        try:\n",
        "            data = json.loads(text)\n",
        "        except Exception as e:\n",
        "            print(\"  JSON íŒŒì‹± ì‹¤íŒ¨, ë¬¸ìì—´ë¡œ ì²˜ë¦¬:\", e)\n",
        "            fragment = text\n",
        "        else:\n",
        "            if (data.get(\"isSuccess\") is False) and (\"error\" in data):\n",
        "                print(\"  âš ï¸ API ì—ëŸ¬ ì‘ë‹µ, ì´ í˜ì´ì§€ëŠ” logNo ì—†ìŒ (message:\",\n",
        "                      data[\"error\"].get(\"message\"), \")\")\n",
        "                continue\n",
        "\n",
        "            found_here = 0\n",
        "\n",
        "            # (1) postList ì•ˆì˜ logNo\n",
        "            if isinstance(data.get(\"postList\"), list):\n",
        "                for post in data[\"postList\"]:\n",
        "                    ln = str(post.get(\"logNo\", \"\")).strip()\n",
        "                    if ln.isdigit():\n",
        "                        post_lognos.add(ln)\n",
        "                        found_here += 1\n",
        "\n",
        "            # (2) í˜¹ì‹œ ëª°ë¼ ë¬¸ìì—´ ì „ì²´ì—ì„œ ì •ê·œì‹ìœ¼ë¡œ í•œ ë²ˆ ë”\n",
        "            fragment_parts = []\n",
        "            for v in data.values():\n",
        "                if isinstance(v, str):\n",
        "                    fragment_parts.append(v)\n",
        "            fragment = html_lib.unescape(\"\".join(fragment_parts))\n",
        "\n",
        "            found_eq  = re.findall(r\"logNo=(\\d+)\", fragment)\n",
        "            found_key = re.findall(r'\"logNo\"\\s*:\\s*(\\d+)', fragment)\n",
        "            for ln in found_eq + found_key:\n",
        "                post_lognos.add(ln)\n",
        "                found_here += 1\n",
        "\n",
        "            print(\"  ì´ í˜ì´ì§€ì—ì„œ ì°¾ì€ logNo ê°œìˆ˜:\", found_here)\n",
        "            continue\n",
        "\n",
        "    # JSON ì•„ë‹ ë•Œ (ê·¸ëƒ¥ ë¬¸ìì—´ì—ì„œ logNo íŒ¨í„´ ì°¾ê¸°)\n",
        "    fragment = html_lib.unescape(text)\n",
        "    found_eq  = re.findall(r\"logNo=(\\d+)\", fragment)\n",
        "    found_key = re.findall(r'\"logNo\"\\s*:\\s*(\\d+)', fragment)\n",
        "    found = found_eq + found_key\n",
        "\n",
        "    print(\"  ì´ í˜ì´ì§€ì—ì„œ ì°¾ì€ logNo ê°œìˆ˜:\", len(found))\n",
        "\n",
        "    for ln in found:\n",
        "        post_lognos.add(ln)\n",
        "\n",
        "# âœ… ìµœì¢… ì •ë¦¬\n",
        "print(\"\\nâœ… ìµœì¢… ìˆ˜ì§‘ëœ logNo ê°œìˆ˜(ì¤‘ë³µ ì œê±° í›„):\", len(post_lognos))\n",
        "\n",
        "post_urls = [\n",
        "    f\"{BASE_BLOG}/PostView.naver?blogId={BLOG_ID}&logNo={ln}\"\n",
        "    for ln in sorted(post_lognos)\n",
        "]\n",
        "\n",
        "print(\"ì˜ˆì‹œ URL 5ê°œ:\")\n",
        "for u in post_urls[:5]:\n",
        "    print(\" \", u)"
      ],
      "metadata": {
        "id": "7vYW04E4aOKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##A-3.  ê° ê²Œì‹œë¬¼ ìƒì„¸ í˜ì´ì§€ì—ì„œ ì •ë³´ ìˆ˜ì§‘ (ì œëª©/ë‚ ì§œ/ëŒ“ê¸€/ì¢‹ì•„ìš”/íƒœê·¸)"
      ],
      "metadata": {
        "id": "RmN4w3IzagY9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###A-3-1. mainFrameê¹Œì§€ ë“¤ì–´ê°€ëŠ” í•¨ìˆ˜"
      ],
      "metadata": {
        "id": "lkNvVnxttUL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#urlë¡œ ì œëª© ê°€ì ¸ì˜¤ê¸°\n",
        "\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 \"\n",
        "                  \"(KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36\",\n",
        "} #ğŸ‘‰â­ï¸ì‚¬ìš©ìì˜ User-Agent ê¸°ì¬\n",
        "\n",
        "def fetch_soup_following_mainframe(url: str) -> BeautifulSoup:\n",
        "    # ìƒëŒ€ê²½ë¡œë©´ ì ˆëŒ€ê²½ë¡œë¡œ\n",
        "    if url.startswith(\"/\"):\n",
        "        full_url = BASE_BLOG + url\n",
        "    else:\n",
        "        full_url = url\n",
        "\n",
        "    res = requests.get(full_url, headers=HEADERS)\n",
        "    res.raise_for_status()\n",
        "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
        "\n",
        "    # í”„ë ˆì„ì…‹ â†’ mainFrame ì•ˆìœ¼ë¡œ í•œ ë²ˆ ë” ë“¤ì–´ê°€ê¸°\n",
        "    iframe = soup.find(\"iframe\", id=\"mainFrame\")\n",
        "    if iframe and iframe.get(\"src\"):\n",
        "        src = iframe[\"src\"]\n",
        "        if src.startswith(\"/\"):\n",
        "            src = BASE_BLOG + src\n",
        "        res2 = requests.get(src, headers=HEADERS)\n",
        "        res2.raise_for_status()\n",
        "        soup = BeautifulSoup(res2.text, \"html.parser\")\n",
        "\n",
        "    return soup\n"
      ],
      "metadata": {
        "id": "TzxWmpNwahNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#í™•ì¸ ì½”ë“œ\n",
        "soup = fetch_soup_following_mainframe(#\"í™•ì¸ìš© í¬ìŠ¤íŠ¸ url ê¸°ì…\")\n",
        "print(soup.title.string)"
      ],
      "metadata": {
        "id": "I-mvfr1ruPjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###A-3-2. ìƒì„¸ ì •ë³´ íŒŒì‹± í•¨ìˆ˜(ì œëª©, ì—…ë¡œë“œ ì¼ì, ëŒ“ê¸€ ìˆ˜)"
      ],
      "metadata": {
        "id": "SRU4xKcKoRGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mainframeì—ì„œ url, ì œëª©, ì—…ë¡œë“œ ì¼ì, ëŒ“ê¸€ ìˆ˜ ê°€ì ¸ì˜¤ê¸°\n",
        "def parse_post_detail(url: str) -> dict:\n",
        "    soup = fetch_soup_following_mainframe(url)\n",
        "\n",
        "\n",
        "    # 1) ì œëª©\n",
        "        title = None\n",
        "    og = soup.find(\"meta\", property=\"og:title\")\n",
        "    if og and og.get(\"content\"):\n",
        "        title = og[\"content\"].strip()\n",
        "    if not title:\n",
        "        t_el = (\n",
        "            soup.select_one(\".pcol1.itemSubjectBoldfont\") or\n",
        "            soup.select_one(\"h3.se_textarea\") or\n",
        "            soup.select_one(\"h2\")\n",
        "        )\n",
        "        if t_el:\n",
        "            title = t_el.get_text(strip=True)\n",
        "\n",
        "\n",
        "    # 2) ì—…ë¡œë“œ ë‚ ì§œ\n",
        "        date = None\n",
        "    d_el = (\n",
        "        soup.select_one(\".se_publishDate\") or\n",
        "        soup.select_one(\".se_publishDate.pcol2\") or\n",
        "        soup.select_one(\"span.t_date\")\n",
        "    )\n",
        "    if d_el:\n",
        "        date = d_el.get_text(strip=True)\n",
        "\n",
        "    full_text = soup.get_text(\" \", strip=True)\n",
        "\n",
        "\n",
        "    # 3) ëŒ“ê¸€ ìˆ˜\n",
        "        comment_count = 0\n",
        "\n",
        "    cmt_el = soup.select_one(\".u_cbox_count, .u_cbox_cnt\")\n",
        "    if cmt_el:\n",
        "        m = re.search(r\"\\d+\", cmt_el.get_text())\n",
        "        if m:\n",
        "            comment_count = int(m.group())\n",
        "\n",
        "    if comment_count == 0:\n",
        "        m = re.search(r\"ëŒ“ê¸€\\s*([0-9][0-9,]*)\", full_text)\n",
        "        if m:\n",
        "            comment_count = int(m.group(1).replace(\",\", \"\"))\n",
        "\n",
        "\n",
        "    return {\n",
        "        \"url\": url,\n",
        "        \"title\": title,\n",
        "        \"date\": date,\n",
        "        \"comment_count\": comment_count\n",
        "    }"
      ],
      "metadata": {
        "id": "MxaLTFCsoPFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ì •ìƒ ì‹¤í–‰ í™•ì¸\n",
        "print(parse_post_detail(#\"í™•ì¸ìš© í¬ìŠ¤íŠ¸ url ê¸°ì…\"))"
      ],
      "metadata": {
        "id": "WgzYgIer5Jsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###A-3-3. ìƒì„¸ ì •ë³´ íŒŒì‹± í•¨ìˆ˜(ê³µê° ìˆ˜)"
      ],
      "metadata": {
        "id": "qsftQxar5wwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ê³µê° ìˆ˜ íŒŒì‹± ìœ„í•´ì„œ HTML ë‚´ span í•¨ìˆ˜ ì°¾ê¸°\n",
        "test_url = #\"í™•ì¸ìš© í¬ìŠ¤íŠ¸ url ê¸°ì…\"\n",
        "\n",
        "soup = fetch_soup_following_mainframe(test_url)\n",
        "\n",
        "# 1) ìš°ë¦¬ê°€ ì›í•˜ëŠ” spanì´ ëª‡ ê°œ ìˆëŠ”ì§€\n",
        "spans = soup.select(\"span.u_likeit_text._count.num\")\n",
        "print(\"ì°¾ì€ ê³µê° span ê°œìˆ˜:\", len(spans))\n",
        "\n",
        "for i, el in enumerate(spans):\n",
        "    print(f\"[{i}] span HTML:\", el)\n",
        "    print(f\"[{i}] span text:\", el.get_text(strip=True))\n",
        "\n",
        "# 2) í˜¹ì‹œë¼ë„ ë¬¸ìì—´ë¡œë§Œ ìˆëŠ”ì§€\n",
        "print(\"'u_likeit_text _count num' in ì „ì²´ HTML? ->\", \"u_likeit_text _count num\" in str(soup))"
      ],
      "metadata": {
        "id": "i-PxdcUOAYlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# JSë¡œ ê³µê° ë¦¬ìŠ¤íŠ¸ ì •ìƒ íŒŒì‹±í•˜ê¸°\n",
        "import requests, time, json\n",
        "\n",
        "\n",
        "HEADERS_API = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 \"\n",
        "                  \"(KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36\",\n",
        "    \"Accept\": \"*/*\",\n",
        "    \"Accept-Language\": \"ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
        "    \"Content-Type\": \"application/x-www-form-urlencoded; charset=utf-8\",\n",
        "    \"Cookie\": \"NNB=...; NID_SES=...; JSESSIONID=...\", #ğŸ‘‰â­ï¸ì‚¬ìš©ìì˜ Cookie ê¸°ì¬\n",
        "    \"Referer\": \"https://blog.naver.com/SympathyHistoryList.naver?blogId=...&logNo=...&layoutWidthClassName=...\", #ğŸ‘‰â­ï¸ì‚¬ìš©ìì˜ Referer ê¸°ì¬\n",
        "}\n",
        "\n",
        "def extract_logno(url: str):\n",
        "    import re\n",
        "    m = re.search(r\"logNo=(\\d+)\", url)\n",
        "    return m.group(1) if m else None\n",
        "\n",
        "test_url = #\"í…ŒìŠ¤íŠ¸ í¬ìŠ¤íŒ… url ê¸°ì…\"\n",
        "logno = extract_logno(test_url)\n",
        "\n",
        "ts = int(time.time() * 1000)\n",
        "api_url = f\"{BASE_BLOG}/api/blogs/{BLOG_ID}/posts/{logno}/sympathy-users\"\n",
        "params = {\"itemCount\": 60, \"timeStamp\": ts}\n",
        "\n",
        "res = requests.get(api_url, headers=HEADERS_API, params=params)\n",
        "print(\"status:\", res.status_code)\n",
        "\n",
        "data = res.json()\n",
        "print(json.dumps(data, ensure_ascii=False, indent=2)[:1200])"
      ],
      "metadata": {
        "id": "FRi8_1B8A3xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TEST URL í†µí•´ ê³µê° ìˆ˜ ì •ìƒ íŒŒì‹± í™•ì¸í•˜ê¸°\n",
        "def get_like_count_via_api(url: str) -> int | None:\n",
        "    logno = extract_logno(url)\n",
        "    if not logno:\n",
        "        print(\"logNo ì¶”ì¶œ ì‹¤íŒ¨:\", url)\n",
        "        return None\n",
        "\n",
        "    ts = int(time.time() * 1000)\n",
        "    api_url = f\"{BASE_BLOG}/api/blogs/{BLOG_ID}/posts/{logno}/sympathy-users\"\n",
        "    params = {\"itemCount\": 1, \"timeStamp\": ts}\n",
        "\n",
        "    res = requests.get(api_url, headers=HEADERS_API, params=params)\n",
        "    if res.status_code != 200:\n",
        "        print(\"API ì—ëŸ¬:\", res.status_code, res.text[:200])\n",
        "        return None\n",
        "\n",
        "    data = res.json()\n",
        "    result = data.get(\"result\")\n",
        "    if not isinstance(result, dict):\n",
        "        print(\"result êµ¬ì¡° ì´ìƒ:\", type(result))\n",
        "        return None\n",
        "\n",
        "    # 1) ê°€ì¥ í”í•œ ì¼€ì´ìŠ¤: totalCount\n",
        "    if \"totalCount\" in result:\n",
        "        try:\n",
        "            return int(result[\"totalCount\"])\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # 2) ë‹¤ë¥¸ ì´ë¦„ì¼ ìˆ˜ë„ ìˆìŒ: sympathyUsersCount, sympathyCount, likeCount ë“±\n",
        "    for key in [\"sympathyUsersCount\", \"sympathyCount\", \"likeCount\"]:\n",
        "        if key in result:\n",
        "            try:\n",
        "                return int(result[key])\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    # 3) sympathyUsers ë°°ì—´ ê¸¸ì´ë¡œ ê³„ì‚°\n",
        "    if \"sympathyUsers\" in result and isinstance(result[\"sympathyUsers\"], list):\n",
        "        return len(result[\"sympathyUsers\"])\n",
        "\n",
        "    print(\"ê³µê° ìˆ˜ í‚¤ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”. result keys:\", list(result.keys()))\n",
        "    return None"
      ],
      "metadata": {
        "id": "su5LAaeDBLS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ëœë¤ urlë¡œ í™•ì¸\n",
        "print(get_like_count_via_api(test_url))"
      ],
      "metadata": {
        "id": "i-MVTxAnBP-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì „ì²´ ê²Œì‹œë¬¼ ê³µê° ìˆ˜ íŒŒì‹±í•˜ê¸°\n",
        "rows = []\n",
        "\n",
        "for url in post_urls:\n",
        "    try:\n",
        "        like_cnt = get_like_count_via_api(url)\n",
        "    except Exception as e:\n",
        "        print(\"ì—ëŸ¬ ë°œìƒ:\", url, \"/\", e)\n",
        "        like_cnt = None\n",
        "\n",
        "    rows.append({\n",
        "        \"url\": url,\n",
        "        \"like_count\": like_cnt,\n",
        "    })\n",
        "\n",
        "df_likes = pd.DataFrame(rows)\n",
        "df_likes.head()"
      ],
      "metadata": {
        "id": "eK879VOTBSEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##A-4. ì „ì²´ ê²Œì‹œë¬¼ DataFrame ë§Œë“¤ê¸°"
      ],
      "metadata": {
        "id": "pA4wXtHPtrBK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### df_detail ìƒì„±(url, title, date, comment_count)"
      ],
      "metadata": {
        "id": "m6erkTIECnVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. df_detail ìƒì„±\n",
        "rows_detail = []\n",
        "\n",
        "for url in post_urls:\n",
        "    try:\n",
        "        info = parse_post_detail(url)   # url, title, date, comment_count ë¦¬í„´\n",
        "    except Exception as e:\n",
        "        print(\"ì—ëŸ¬ ë°œìƒ:\", url, \"/\", e)\n",
        "        continue\n",
        "    rows_detail.append(info)\n",
        "\n",
        "df_detail = pd.DataFrame(rows_detail)\n",
        "df_detail.head()"
      ],
      "metadata": {
        "id": "vgKb5swNDMD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### df_merged ìƒì„± (df_detail + like_count)"
      ],
      "metadata": {
        "id": "12AcwjzKI47d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#2. df_likes ìƒì„± ë° df_detailê³¼ merge\n",
        "df_merged = df_detail.merge(df_likes, on=\"url\", how=\"left\")\n",
        "df_merged.head()"
      ],
      "metadata": {
        "id": "poAKxmb5DRNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**B. 1-5ë²ˆ ìˆ˜ì¹˜ ì‚°ì¶œ**\n",
        "\n",
        "    1. ì´ ê²Œì‹œë¬¼ ìˆ˜\n",
        "    2. ì´ ëŒ“ê¸€ ìˆ˜\n",
        "    3. ì´ ì¢‹ì•„ìš” ìˆ˜\n",
        "    4. ê²Œì‹œë¬¼ 1ê±´ ë‹¹ í‰ê·  ëŒ“ê¸€ ìˆ˜\n",
        "    5. ê²Œì‹œë¬¼ 1ê±´ ë‹¹ í‰ê·  ì¢‹ì•„ìš” ìˆ˜"
      ],
      "metadata": {
        "id": "5UtvU1zNU4s_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged.info()"
      ],
      "metadata": {
        "id": "xmR4hDt7KHGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NaN â†’ 0ìœ¼ë¡œ ë°”ê¿”ë‘ëŠ” ê²Œ ê¹”ë”\n",
        "df_merged[\"comment_count\"] = df_merged[\"comment_count\"].fillna(0).astype(int)\n",
        "df_merged[\"like_count\"]    = df_merged[\"like_count\"].fillna(0).astype(int)\n",
        "\n",
        "# 5. ì´ ê²Œì‹œë¬¼ ìˆ˜\n",
        "total_posts = len(df_merged)\n",
        "\n",
        "# 6. ì´ ëŒ“ê¸€ ìˆ˜\n",
        "total_comments = df_merged[\"comment_count\"].sum()\n",
        "\n",
        "# 7. ì´ ì¢‹ì•„ìš” ìˆ˜\n",
        "total_likes = df_merged[\"like_count\"].sum()\n",
        "\n",
        "# 8. ê²Œì‹œë¬¼ 1ê±´ ë‹¹ í‰ê·  ëŒ“ê¸€ ìˆ˜\n",
        "avg_comments_per_post = total_comments / total_posts if total_posts > 0 else np.nan\n",
        "\n",
        "# 9. ê²Œì‹œë¬¼ 1ê±´ ë‹¹ í‰ê·  ì¢‹ì•„ìš” ìˆ˜\n",
        "avg_likes_per_post = total_likes / total_posts if total_posts > 0 else np.nan\n",
        "\n",
        "print(\"ì´ ê²Œì‹œë¬¼ ìˆ˜:\", total_posts)\n",
        "print(\"ì´ ëŒ“ê¸€ ìˆ˜:\", total_comments)\n",
        "print(\"ì´ ì¢‹ì•„ìš” ìˆ˜:\", total_likes)\n",
        "print(\"ê²Œì‹œë¬¼ 1ê±´ ë‹¹ í‰ê·  ëŒ“ê¸€ ìˆ˜:\", avg_comments_per_post)\n",
        "print(\"ê²Œì‹œë¬¼ 1ê±´ ë‹¹ í‰ê·  ì¢‹ì•„ìš” ìˆ˜:\", avg_likes_per_post)"
      ],
      "metadata": {
        "id": "C-oz50wdKJnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**C. ì¶”ê°€ ê¸°ì´ˆ ì§€í‘œ**\n",
        "\n",
        "    1. \tëŒ“ê¸€/ê³µê° ë¶„í¬ (ì¤‘ì•™ê°’, ë¶„ìœ„ìˆ˜, 0ê°œ ë¹„ìœ¨)\n",
        "\t2.\tì‹œê°„ì¶•(ì—°ë„/ì›”ë³„, ìµœê·¼ 6~12ê°œì›” ê¸°ì¤€) ì§€í‘œ\n"
      ],
      "metadata": {
        "id": "eplGKen0fNYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###C-1. ëŒ“ê¸€/ê³µê° ë¶„í¬ (ì¤‘ì•™ê°’, ë¶„ìœ„ìˆ˜, 0ê°œ ë¹„ìœ¨)"
      ],
      "metadata": {
        "id": "76Fp-3eGgQjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0) ì•ˆì „í•˜ê²Œ íƒ€ì…/ê²°ì¸¡ì¹˜ ì²˜ë¦¬\n",
        "df_merged[\"comment_count\"] = df_merged[\"comment_count\"].fillna(0).astype(int)\n",
        "df_merged[\"like_count\"]    = df_merged[\"like_count\"].fillna(0).astype(int)\n",
        "\n",
        "# 1) ëŒ“ê¸€ ë¶„í¬ ìš”ì•½ (ëŒ“ê¸€ ìˆ˜)\n",
        "comment_stats = df_merged[\"comment_count\"].describe(percentiles=[0.25, 0.5, 0.75, 0.9])\n",
        "print(\"ğŸ“Œ ëŒ“ê¸€ ë¶„í¬ ìš”ì•½\")\n",
        "print(comment_stats)\n",
        "print()\n",
        "\n",
        "# 2) ê³µê°(ì¢‹ì•„ìš”) ë¶„í¬ ìš”ì•½ (like_count)\n",
        "like_stats = df_merged[\"like_count\"].describe(percentiles=[0.25, 0.5, 0.75, 0.9])\n",
        "print(\"ğŸ“Œ ê³µê°(ì¢‹ì•„ìš”) ë¶„í¬ ìš”ì•½\")\n",
        "print(like_stats)\n",
        "print()\n",
        "\n",
        "# 3) ëŒ“ê¸€/ê³µê° 0ê°œì¸ ê¸€ ë¹„ìœ¨\n",
        "zero_comment_ratio = (df_merged[\"comment_count\"] == 0).mean()\n",
        "zero_like_ratio    = (df_merged[\"like_count\"] == 0).mean()\n",
        "\n",
        "print(f\"ğŸ’¬ ëŒ“ê¸€ 0ê°œì¸ ê¸€ ë¹„ìœ¨: {zero_comment_ratio:.2%}\")\n",
        "print(f\"â¤ï¸ ê³µê° 0ê°œì¸ ê¸€ ë¹„ìœ¨: {zero_like_ratio:.2%}\")\n",
        "\n",
        "# 4) ìƒìœ„ 10% ê¸°ì¤€ ì„ê³„ê°’ë„ ë³´ê³  ì‹¶ë‹¤ë©´ (ì„ íƒ)\n",
        "comment_top10_threshold = df_merged[\"comment_count\"].quantile(0.9)\n",
        "like_top10_threshold    = df_merged[\"like_count\"].quantile(0.9)\n",
        "\n",
        "print()\n",
        "print(f\"ğŸ’¬ ëŒ“ê¸€ ìˆ˜ ìƒìœ„ 10% ê¸°ì¤€ ì„ê³„ê°’(ëŒ€ëµ): {comment_top10_threshold}\")\n",
        "print(f\"â¤ï¸ ê³µê° ìˆ˜ ìƒìœ„ 10% ê¸°ì¤€ ì„ê³„ê°’(ëŒ€ëµ): {like_top10_threshold}\")"
      ],
      "metadata": {
        "id": "bmrlm1sBgjU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###C-2. ì‹œê°„ì¶•(ì—°ë„/ì›”ë³„, ìµœê·¼ 6~12ê°œì›” ê¸°ì¤€) ì§€í‘œ"
      ],
      "metadata": {
        "id": "zjL-NHRLATUc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ë‚ ì§œë¥¼ datetimeìœ¼ë¡œ ë³€í™˜í•˜ê¸°"
      ],
      "metadata": {
        "id": "gxj8bwrcAlvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# í˜¹ì‹œ ëª¨ë¥¼ ê²°ì¸¡Â·íƒ€ì… ì²˜ë¦¬\n",
        "df_merged[\"comment_count\"] = df_merged[\"comment_count\"].fillna(0).astype(int)\n",
        "df_merged[\"like_count\"]    = df_merged[\"like_count\"].fillna(0).astype(int)\n",
        "\n",
        "# 'date' ì˜ˆì‹œ: \"2023. 5. 14. 17:31\"\n",
        "# ë¬¸ìì—´ â†’ datetime\n",
        "df_merged[\"dt\"] = pd.to_datetime(df_merged[\"date\"], errors=\"coerce\")\n",
        "\n",
        "# ë‚ ì§œ íŒŒì‹± ì•ˆ ëœ í–‰ì€ ì ê¹ ë²„ë¦¬ì (ê·¹ì†Œìˆ˜ì¼ ê°€ëŠ¥ì„± í¼)\n",
        "df_time = df_merged.dropna(subset=[\"dt\"]).copy()"
      ],
      "metadata": {
        "id": "QLKVg-lxATpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ì—°ë„ë³„ ì§€í‘œ\n",
        "    * ì—°ë„ë³„ ê²Œì‹œë¬¼ ìˆ˜\n",
        "    * ì—°ë„ë³„ í‰ê·  ëŒ“ê¸€ ìˆ˜ / í‰ê·  ê³µê° ìˆ˜"
      ],
      "metadata": {
        "id": "MeM3HVnbAqfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_time[\"year\"] = df_time[\"dt\"].dt.year\n",
        "\n",
        "yearly_stats = (\n",
        "    df_time\n",
        "    .groupby(\"year\")\n",
        "    .agg(\n",
        "        posts=(\"url\", \"count\"),\n",
        "        avg_comments=(\"comment_count\", \"mean\"),\n",
        "        avg_likes=(\"like_count\", \"mean\"),\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "print(\"ğŸ“† ì—°ë„ë³„ í†µê³„\")\n",
        "print(yearly_stats)"
      ],
      "metadata": {
        "id": "AiDNVsIWAjvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ì—°-ì›”ë³„ ì§€í‘œ (ì›” ë‹¨ìœ„ ì¶”ì´)\n",
        " \t* ì›”ë³„ ê²Œì‹œë¬¼ ìˆ˜\n",
        "\t* ì›”ë³„ í‰ê·  ëŒ“ê¸€ / ê³µê° ìˆ˜"
      ],
      "metadata": {
        "id": "0TflPgDRA3D1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ì—°-ì›” ë¬¸ìì—´ ì»¬ëŸ¼ (ì˜ˆ: 2023-05)\n",
        "df_time[\"year_month\"] = df_time[\"dt\"].dt.to_period(\"M\").astype(str)\n",
        "\n",
        "monthly_stats = (\n",
        "    df_time\n",
        "    .groupby(\"year_month\")\n",
        "    .agg(\n",
        "        posts=(\"url\", \"count\"),\n",
        "        avg_comments=(\"comment_count\", \"mean\"),\n",
        "        avg_likes=(\"like_count\", \"mean\"),\n",
        "    )\n",
        "    .reset_index()\n",
        "    .sort_values(\"year_month\")\n",
        ")\n",
        "\n",
        "print(\"ğŸ“† ì›”ë³„ í†µê³„ (ì—°-ì›” ë‹¨ìœ„)\")\n",
        "print(monthly_stats.tail)  # ìµœê·¼ 12ê°œì›”ë§Œ í™•ì¸í•´ë³´ê¸°"
      ],
      "metadata": {
        "id": "Bjvakft7A2Am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ìµœê·¼ 6ê°œì›” / 12ê°œì›” ë¶„ì„"
      ],
      "metadata": {
        "id": "uLWeaggVBP8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latest_date = df_time[\"dt\"].max()\n",
        "cut_6m  = latest_date - pd.DateOffset(months=6)\n",
        "cut_12m = latest_date - pd.DateOffset(months=12)\n",
        "\n",
        "recent_6m  = df_time[df_time[\"dt\"] >= cut_6m]\n",
        "recent_12m = df_time[df_time[\"dt\"] >= cut_12m]\n",
        "\n",
        "def summarize_period(name, df):\n",
        "    n_posts = len(df)\n",
        "    total_comments = df[\"comment_count\"].sum()\n",
        "    total_likes    = df[\"like_count\"].sum()\n",
        "    avg_c = total_comments / n_posts if n_posts > 0 else np.nan\n",
        "    avg_l = total_likes / n_posts if n_posts > 0 else np.nan\n",
        "\n",
        "    print(f\"ğŸ”¹ {name}\")\n",
        "    print(\"  ê¸°ê°„:\", df[\"dt\"].min(), \"~\", df[\"dt\"].max())\n",
        "    print(\"  ê²Œì‹œë¬¼ ìˆ˜:\", n_posts)\n",
        "    print(\"  ì´ ëŒ“ê¸€ ìˆ˜:\", total_comments)\n",
        "    print(\"  ì´ ê³µê° ìˆ˜:\", total_likes)\n",
        "    print(\"  ê¸€ë‹¹ í‰ê·  ëŒ“ê¸€ ìˆ˜:\", avg_c)\n",
        "    print(\"  ê¸€ë‹¹ í‰ê·  ê³µê° ìˆ˜:\", avg_l)\n",
        "    print()\n",
        "\n",
        "summarize_period(\"ìµœê·¼ 6ê°œì›”\", recent_6m)\n",
        "summarize_period(\"ìµœê·¼ 12ê°œì›”\", recent_12m)"
      ],
      "metadata": {
        "id": "l535iQ4AA2fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QBPDuaGHBPhZ"
      }
    }
  ]
}